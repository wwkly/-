# 吃瓜笔记

## 第一章	绪论

绪论开篇介绍了一些重要的术语概念：

1. 样本（示例），行向量，列向量，样本空间；
2. 数据集，训练集，测试集，训练，测试，模型，假设，真相；
3. 标记，标记空间；
4. 泛化，分布；
5. 分类，回归，聚类；
6. 监督学习，无监督学习；
7. 假设空间，版本空间，归纳偏好

在学习过程中，很多概念在经过西瓜书和南瓜书形象的解释后很容易理解；



从假设空间内容开始的展开容易让人产生较深的印象：

1. 对于训练集，因其有限性，都可能会有不同的假设是符合的，这就称为是不同的假设空间；不同假设空间的集合就是版本空间；		但是，有那么多假设空间，对于非训练集样本的预测往往不同，那么就会产生一个问题：在进行测试时，应该用哪个呢？		接着这个问题，随后引出了归纳偏好的必要性以及对NFL原理的论证。
2. 既然不同假设空间所产生的预测可能不同，那么我们在进行预测时应该具体问题具体分析，鱼与熊掌不可兼得，但是我们应该选择我们更需要的那个；         在选择假设空间问题中有一个“奥卡姆剃刀”原则，它偏向更简单的假设空间，这其实并不是很好的答案，一者它似乎与具体问题没有关联，二者有时很难定义何为“简单”。
3. 式1.1，1.2推导出一个令人不解的答案：总误差与学习算法没有关系；这与常人思想中的“越好越精密的东西越厉害”不同。这就是NFL（天下没有免费午餐）定理。但这是在基于“问题”出现几率相同，重要程度相同的基础上。幸运的是，我们想要解决的问题往往不符合上面的定义，不同问题出现的几率不同，重要程度也不同，即我们需要找到最能解决我们需求的那个算法。



绪论后面介绍了机器学习等领域在人类社会发展，人们生活中的重要性。有些是我们正在亲历的，有些还亟待发展，相信这个领域会继续发光，也带来一些学习的动力吧。

------



## 第二章

### 2.1 经验误差与过拟合

概念：

1. 错误率，精度		精度=1-错误率
2. 误差，经验误差，泛化误差
3. 过拟合，欠拟合

过拟合：学习能力相比于数据太强也不是一件好事，如果学习器在训练集中挖掘过深，就可能把训练集中的很多特点找出，认为这是预测真相的一些规律。然而，这些特点可能并不适用于潜在样本，因此可能造成泛化误差反而变大的结果，这就是过拟合。

欠拟合：相对于过拟合，欠拟合就是寻常理解的功夫不到位导致的误差大。

由于过拟合现象的存在，并且是不可避免的。因此成为了机器学习很多地方的关键障碍。

一个任务，可以选择多种算法；一个算法，可以选择多种参数配置；这造成了模型的选择多样，如何选择到最适合的呢？这就是模型的选择问题。关于这个问题，观察误差大小似乎可以评价模型的好坏，然而，无论是泛化误差还是训练误差都有它适合作为现实评价的理由：

1. 对于泛化误差：我们无法得到泛化误差
2. 对于训练误差：由于可能存在过拟合现象，训练误差的大小难以推理出泛化误差的大小

由此引出第二节介绍评估方法。

------



### 2.2评估方法

上节中的主要问题在于，泛化误差难以获取。所以采取这样一种方法：

找到一个”测试集“来测试训练得到的学习器，根据在这个测试集上的测试误差来作为泛化误差的近似；这里通常要有两个原则：

1. 测试集应该尽可能的与训练集互斥，即测试集中的样本不作为训练过程的材料
2. 测试集的样本理应也是独立同分布采样而得，以让其测试误差具有能够近似泛化误差的条件

一般在任务中，样本数据只有那么多，只能将样本进行划分，划分为训练集和测试集；如何对总的数据集进行划分，这里介绍了几种方法：

1. 留出法：即留出一部分样本作为测试集不参与训练，测试集与训练集在分布上应尽可能一致（保留类别比例）；如何留出这部分样本仍有很多种方法，如从1000个样本中留出300个，留下哪300个还是有很多组合方法；所以一般采用若干此留出法最后取平均值。（为保证训练集或是测试集不过少，一般取一个折中的比例，以2/3到4/5的样本做训练）
2. 交叉验证法：交叉验证法相比留出法的不同是，按照分层采样将数据集分为k个子集，在一次交叉验证法中，分别以各个子集作为测试集，其他子集作为训练集，可以得到k组测试结果，也叫k折交叉验证；即使是这样，从数据集划分为k个子集的过程中依旧有很多种组合方法，与留出法类似，也应进行若干次k折验证法最后取平均值。
3. 留一法：交叉验证法的特例，有多少样本就分为多少子集，也就会在一次方法中产生多少次训练和测试，这个开销是巨大的，而且最后的结果也不一定理想。
4. 自助法：上面的方法都减小了数据集的规模，训练集不足会导致一些偏差。这里采用放回抽取的方法，从数据集中抽样本再放回，直到抽出的样本数与原数据集一样大，根据计算，样本不被抽取的概率约为36.8%，保证了训练集与测试集的互斥。但是样本的重复抽取会改变训练集相比原数据集的分布，这是会产生偏差的。

上面，我们把划分出的部分叫做测试集，但是，实际使用学习器时遇到的数据也是在对学习器进行测试，这里，我们把上面从数据集划分出来的测试集叫做验证集，相应的测试过程也叫做验证。

因此现在我们就有了数据集（划分为训练集，验证集）作为得到模型的材料，有模型得到后进行评估测试的测试集。

其实这里的测试集一般还是要我们提前留出的，关系可以见下：

![img](images/%E4%B8%BA%E4%BB%BB%E5%8A%A1%E5%87%86%E5%A4%87%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86.png)

我们利用最后的训练集训练模型，使用验证集来检验不同算法，不同参数配置时模型的好坏，选择到最好的一组后。使用测试集来对模型进行检验，估测测试误差（近似泛化误差）来评估模型。

------

### 2.3性能度量

概念：

1. 均方误差，错误率，精度
2. 查准率，查全率，分类结果混淆矩阵
3. P-R曲线，P-R图，BEP，F1，Fβ
4. 宏查准率，宏查全率，宏F1；微查准率，微查全率，微F1
5. 分类阈值，ROC曲线；TPR，FPR，TNR，FNR；AUC，损失
6. 代价矩阵，代价曲线，归一化代价

对于P-R，ROC，代价，可以理解后自己举例，画图描点连线画一画

2.3-后，有点不太想看了，浏览了一遍，后续重新学习时再补充

[^两节内容补充]: 2.4，2.5部分内容后续补充

[南瓜书学习教程网站主页]: https://www.datawhale.cn/home

[^西瓜书]: 西瓜书就是周志华老师的《机器学习》



